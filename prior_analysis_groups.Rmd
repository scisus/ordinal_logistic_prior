---
title: "Choosing priors in an ordinal logistic model"
subtitle: "with covariate and group effects"
author: "Susannah Tysor"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    theme: flatly
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r}
library(dplyr)
library(rstan)
library(tidyr)
library(purrr)
library(cowplot)
library(bayesplot)

rstan_options(auto_write=TRUE)
```
# Background

[Previously](https://scisus.github.io/ordinal_logistic_prior/prior_analysis.html), I considered whether a gamma or an induced dirichlet prior on cut points in an ordinal logistic model worked better for the kind of data I'm considering.

In this model, the state of flowering depends on how many forcing units have accumulated. 

There are three possible states: 1-not yet flowering, 2- flowering, 3- done flowering. 

$x$ is accumulated forcing: when flowering was observed, how much warmth had the population/tree been exposed to since January 1? $x$ is always positive (and always increases monotonically through time - though time is abstracted out of this model).

$\beta$ describes how fast the transition occurs - small $\beta$s make the transition from between states occur over a wider range of $x$'s. (Translated from forcing units to days, this answers a question like "does the population transition between states over 1 day, 3 days, a week?" We work in forcing unit space because the trees respond to temperature, not time - and no spring heats up exactly the same so dates are kind of useless for prediction.) $\beta$ is always positive.

A gamma prior on cut points that's got a distribution fat enough to encompass the entire possible range of cut points worked well. An induced dirichlet prior on cut points only works well when it is anchored near the first cut point and when cut points are relatively close together. While the model with an induced dirichlet prior can struggle to recapture $\beta$ and cut points $c$, it is pretty good at capturing the relationship between $\beta$ and $c$: $h = \frac{c}{\beta}$, which is the point at which half the trees in a population have transitioned or the point at which an individual tree is 50% likely to have transitioned. 

In the previous analysis, no groups were considered. In reality, I want to know if site, provenance, and clone affect $h$.

## Goals
1 - Generate data with an ordinal logistic model 
 a - With linear model structure $(\beta + \beta_{site_i}) x$
 b - With linear model structure $\beta x + \alpha$
2 - Fit both models
3 - Determine whether $\beta$, \beta_{site_i}$, \alpha$, $c$, or $h$ can be returned.

# Simulate site effects

Let's simulate 7 groups with `N=100` observations for each group. Each group's $h$ are shifted by $h_mod$, which is drawn from a standard normal distribution.

```{r}
hist(rnorm(1000), breaks=20)
```


```{r group simulation}



#h_mod <- rnorm(G=7, 0, hsd=1) # how much being in each group modifies half transitions
h_mod <- c(  0.35, -0.52, -1.32, -0.72, -0.78,  0.73, -0.45)
simulation_input <- set_simulation_parameters()

# simulate from models with identical transition points, but effects on alpha or beta

simulate_data <- function(input, modification) {
  # simulate data
  if (modification == "beta") {
    simu <- rstan::stan(file='simulate/covar_group_beta_sim.stan', iter=1, chains=1, algorithm="Fixed_param", data=input)
  } 
  if (modification == "alpha") {
    simu <- rstan::stan(file='simulate/covar_group_alpha_sim.stan', iter=1, chains=1, algorithm="Fixed_param", data=input)
  }
  
  # extract data from stan model
  simu_params <- data.frame(rstan::extract(simu)$y[1,,]) %>%
    mutate(x = input$x) %>%
    pivot_longer(cols = -x, names_to = "group", values_to = "y") %>%
    extract(group, into = "group", regex = "([:digit:])") %>%
    mutate(group = as.integer(group))
  
  # format data as input to another stan model
  
  input_data_for_model <- list("N" = input$N * input$G, "K" = input$K, "G" = input$G, "x" = simu_params$x, "y" = simu_params$y, "group" = simu_params$group)
  
  return(input_data_for_model)
}


  

simdat_beta <- map(simulation_input$inputlist, simulate_data, modification = "beta")  
names(simdat_beta) <- paste(names(simdat_beta), "beta")
simdat_alpha <- map(simulation_input$inputlist, simulate_data, modification = "alpha")
names(simdat_alpha) <- paste(names(simdat_alpha), "alpha")
# simdat <- list()
# simdat <- append(simdat, simdat_beta)
# simdat <- append(simdat, simdat_alpha)

# Plot simulated data to make sure it's reasonable
plot_simulated_data <- function(simdat, simulation_input) {
    # format for plotting
    simdf <- purrr::map(simdat, .f = function(x) {x[c("x", "y", "group")]}) %>%
        purrr::map_dfr(.f = bind_rows, .id=".id")

    # scatterplot
    p1 <- ggplot(simdf, aes(x=x, y=y)) +
        geom_jitter(shape=1, height=0.1, alpha=0.5) +
        ggtitle("Simulated data") +
        facet_grid(group ~ .id)

    # cumulative plot
    p2 <- ggplot(simdf, aes(x=x, colour=as.factor(y))) +
        stat_ecdf() +
        theme(legend.position = "none") +
        ggtitle("Cumulative x for 3 states") +
        facet_grid(group ~ .id)

    cowplot::plot_grid(p1, p2, nrow=2)
}

plot_simulated_data(simdat_beta, simulation_input$inputlist)
plot_simulated_data(simdat_alpha, simulation_input$inputlist)
```

# Recapture

Can the parameter values be recaptured when a model with an induced dirichlet prior for the cut points is used?

```{r params}

beta_rate <- c(1:3) # rate parameters for exponential prior on beta
anchor <- c(10, 20) # different anchor parameters for induced dirichlet prior

# make a nice dataframe with all combinations params used to simulate data and model params used to try to recover those params
# 

parframe_indir <- simulation_input$pars %>% 
  dplyr::select(transition, beta, c.1, c.2, group, alpha_group) %>%
  tidyr::pivot_wider(names_from = group, names_prefix = "alpha_g.", values_from = alpha_group) %>% # put in wide format
  merge(y= beta_rate) %>%
    rename(beta_rate=y) %>%
    merge(y=anchor) %>%
    rename(anchor=y)
parframe_indir$modelid <- 1:nrow(parframe_indir) #label the models

# make a wide format with beta_group cols and merge with parframe_indir

# format parframe so it works with parLapply better
make_parframe_list <- function(parframe) {
    parlist <- split(parframe, seq(nrow(parframe)))
    names(parlist) <- parframe$modelid

    return(parlist)
}
parlist_indir <- make_parframe_list(parframe_indir)
```

```{r indirRecapture, include=FALSE}
# fit a model with an induced dirichlet prior on cutpoints in stan. simdatlist is a list of simulated data (1 simulated dataset per list entry), pars is a list of parameter values (1 set of parameter values per list entry) and groups is TRUE or FALSE indicating whether you're trying to fit groups.
fit_indir_model <- function(simdatlist, pars, modification) {
    #choose whether to use data simulated with a rapid or slow transition
    if (pars$transition == "medium") {
        simdat <- simdatlist$medium
    }
    if (pars$transition == "fast") {
        simdat <- simdatlist$fast
    }
    #extract parameters for prior distributions
    simdat$anchor <- pars$anchor
    simdat$beta_rate <- pars$beta_rate

    #fit the model
    if (modification == "beta") {
        fitindir <- stan(file='induced_dirichlet/dirichlet_covar_beta_group.stan', data=simdat, chains=4)
    } else {
        fitindir <- stan(file='induced_dirichlet/dirichlet_covar_alpha_group.stan', data=simdat, chains=4)
    }
    return(fitindir)
}

# run all models, parallelized

# make a cluster using half your cores
no_cores <- parallel::detectCores()/2
cl <- parallel::makeCluster(no_cores)

# export the stuff you need to run on the cluster
parallel::clusterExport(cl, c("fit_indir_model", "parlist_indir", "simdat_beta", "simdat_alpha"))
parallel::clusterEvalQ(cl, c(library(rstan), library(StanHeaders)))

reps=10
for (i in 1:reps) {
  fits_indir <- parallel::parLapply(cl, parlist_indir, function(x) {fit_indir_model(simdatlist = simdat_beta, pars=x, modification="beta")})
  saveRDS(fits_indir, file = paste0("induced_dirichlet/group_runs/beta_dat_beta_mod/run", i, ".rds"))
  rm(fits_indir)
  gc()
}

for (i in 1:reps) {
    fits_indir <- parallel::parLapply(cl, parlist_indir, function(x) {fit_indir_model(simdatlist = simdat_beta, pars=x, modification="alpha")})
  saveRDS(fits_indir, file = paste0("induced_dirichlet/group_runs/beta_dat_alpha_mod/run", i, ".rds"))
  rm(fits_indir)
  gc()
}

for (i in 1:reps) {  
    fits_indir <- parallel::parLapply(cl, parlist_indir, function(x) {fit_indir_model(simdatlist = simdat_alpha, pars=x, modification="beta")})
  saveRDS(fits_indir, file = paste0("induced_dirichlet/group_runs/alpha_dat_beta_mod/run", i, ".rds"))
  rm(fits_indir)
  gc()
}

for (i in 1:reps) {  
    fits_indir <- parallel::parLapply(cl, parlist_indir, function(x) {fit_indir_model(simdatlist = simdat_alpha, pars=x, modification="alpha")})
  saveRDS(fits_indir, file = paste0("induced_dirichlet/group_runs/alpha_dat_alpha_mod/run", i, ".rds"))
  rm(fits_indir)
  gc()
}

parallel::stopCluster(cl) #close the cluster

```

```{r readIndirModels, warning=FALSE, cache=TRUE}

# pull in parameters and info on divergences, etc from saved stanfit objects
# very slow step. consider parallelizing to the extent your ram can handle
# 
## append a label (string) to all columnnames in a dataframe (x)
label_names <- function(x, label) {
    colnames(x) <- paste0(colnames(x), "_", label)
    return(x)
}

# make_long_param <- function(params) {
#   params <- params %>%
#     pivot_longer(starts_with("alpha"), names_to = "group", values_to = "alpha_group") %>%
#       extract(group, regex="([:digit:])", into = "group")
#   return(params)
# }



calc_h <- function(pars, type) {
  if (type == "beta") {
    newpars <- pars %>%
      mutate(h.1_group.1 = c.1/(beta + beta_g.1),
             h.1_group.2 = c.1/(beta + beta_g.2),
             h.1_group.3 = c.1/(beta + beta_g.3),
             h.1_group.4 = c.1/(beta + beta_g.4),
             h.1_group.5 = c.1/(beta + beta_g.5),
             h.1_group.6 = c.1/(beta + beta_g.6),
             h.1_group.7 = c.1/(beta + beta_g.7),
             
             h.2_group.1 = c.2/(beta + beta_g.1),
             h.2_group.2 = c.2/(beta + beta_g.2),
             h.2_group.3 = c.2/(beta + beta_g.3),
             h.2_group.4 = c.2/(beta + beta_g.4),
             h.2_group.5 = c.2/(beta + beta_g.5),
             h.2_group.6 = c.2/(beta + beta_g.6),
             h.2_group.7 = c.2/(beta + beta_g.7)
      )
  }
  
  if (type == "alpha") {
    newpars <- pars %>%
      mutate(h.1_group.1 = (c.1 + alpha_g.1)/beta,
             h.1_group.2 = (c.1 + alpha_g.2)/beta,
             h.1_group.3 = (c.1 + alpha_g.3)/beta,
             h.1_group.4 = (c.1 + alpha_g.4)/beta,
             h.1_group.5 = (c.1 + alpha_g.5)/beta,
             h.1_group.6 = (c.1 + alpha_g.6)/beta,
             h.1_group.7 = (c.1 + alpha_g.7)/beta,
             
             h.2_group.1 = (c.2 + alpha_g.1)/beta,
             h.2_group.2 = (c.2 + alpha_g.2)/beta,
             h.2_group.3 = (c.2 + alpha_g.3)/beta,
             h.2_group.4 = (c.2 + alpha_g.4)/beta,
             h.2_group.5 = (c.2 + alpha_g.5)/beta,
             h.2_group.6 = (c.2 + alpha_g.6)/beta,
             h.2_group.7 = (c.2 + alpha_g.7)/beta)
  }
  return(newpars)
}

# calc_true_h <- function(truepars) {
#   newtruepars <- truepars %>%
#     mutate(h.1_group.1 = (c.1 + alpha_g.1)/beta,
#            h.1_group.2 = (c.1 + alpha_g.2)/beta,
#            h.1_group.3 = (c.1 + alpha_g.3)/beta,
#            h.1_group.4 = (c.1 + alpha_g.4)/beta,
#            h.1_group.5 = (c.1 + alpha_g.5)/beta,
#            h.1_group.6 = (c.1 + alpha_g.6)/beta,
#            h.1_group.7 = (c.1 + alpha_g.7)/beta,
#            
#            h.2_group.1 = (c.2 + alpha_g.1)/beta,
#            h.2_group.2 = (c.2 + alpha_g.2)/beta,
#            h.2_group.3 = (c.2 + alpha_g.3)/beta,
#            h.2_group.4 = (c.2 + alpha_g.4)/beta,
#            h.2_group.5 = (c.2 + alpha_g.5)/beta,
#            h.2_group.6 = (c.2 + alpha_g.6)/beta,
#            h.2_group.7 = (c.2 + alpha_g.7)/beta)
#   return(newtruepars)
# }

#bind true parameters (in list parlist) and model parameters (in list fit) even tho it will make a giant df. modelstr is string "alpha" or "beta" and describes whether model structure adds effects to intercept or slope.
bind_true_model_pars <- function(fits, parlist, modelstr) {
    # extract params from model object
    params <- lapply(fits, function(x) {data.frame(rstan::extract(x) ) } )
   
    # calculate transitions
    params <- map(params, calc_h, type=modelstr)
    parlist <- map(parlist, calc_h, type=modelstr)

    # label params as coming from the model or as true params used to
    params <- map(params, label_names, label="model")
    parlist <- map(parlist, label_names, label="true")

    # combine model and true params in a big list of dataframes - each list entry is a dataframe for a single model
    params <- map2(params, parlist, cbind)

    return(params)
}

# take a stan object and find out if there's anything egregiously wrong with it
check_model <- function(stanobj) {
    nuts <- nuts_params(stanobj)
    divergences <- dplyr::filter(nuts, Parameter=="divergent__" & Value==1) %>%
        nrow()
    rhats <- rhat(stanobj)
    bad_rhats <- sum(rhats > 1.01)
    nefrats <- neff_ratio(stanobj)
    bad_neff <- sum(nefrats < 0.1, is.nan(nefrats), na.rm=TRUE)
    diagnostics <- data.frame(divergences = divergences, bad_rhats=bad_rhats, bad_neff=bad_neff)
    return(diagnostics)
}

# run check_model on a list of models and add a column that names each row by the list name
check_list_of_models <- function(model_list) {
    map_dfr(model_list, check_model, .id=".id") %>%
        rename(modelid=.id)
}

# Extract model configurations and the most obvious problems with fit/convergence from stanfit objects. Stanfit objects are in lists in .rds files saved in path. path is a string denoting the directory where the rds files are stored. Nothing other than .rds files with lists of stanfit objects should be stored in path.
extract_pars_and_problems <- function(path, parlist, modelstr = modelstr) {
    fits <- list.files(path=path)
    reps <- length(fits)
    pars <- list()
    bad_models <- list()

    for (i in 1:reps) {
        run <- readRDS(paste0(path, fits[i])) # read in first run
        run_pars <- bind_true_model_pars(run, parlist=parlist, modelstr = modelstr) # extract parameters
        run_fit <- check_list_of_models(run) %>% # id problems
            mutate(all_bads = divergences + bad_rhats + bad_neff) %>%
            filter(all_bads > 0) %>%
            select(-all_bads)
        pars[[i]] <- run_pars
        bad_models[[i]] <- run_fit
        rm(run, run_pars, run_fit)
        gc()
    }

    return(list(pars = pars, problems = bad_models))
}

dirs <- list.dirs("induced_dirichlet/group_runs/")
extracts_indir_beta_beta <- extract_pars_and_problems(path="induced_dirichlet/group_runs/beta_dat_beta_mod/", parlist=parlist_indir, modelstr = "beta")
extracts_indir_beta_alpha <- extract_pars_and_problems(path="induced_dirichlet/group_runs/beta_dat_alpha_mod/", parlist=parlist_indir, modelstr = "alpha")
extracts_indir_alpha_beta <- extract_pars_and_problems(path="induced_dirichlet/group_runs/alpha_dat_beta_mod/", parlist=parlist_indir, modelstr = "beta")
extracts_indir_alpha_alpha <- extract_pars_and_problems(path="induced_dirichlet/group_runs/alpha_dat_alpha_mod/", parlist=parlist_indir, modelstr = "alpha")


```

Models with the effect on the slope have serious fitting issues. Lots of divergences. Models with the effect on intercept don't have fitting problems.

```{r indirModelCheck}

table_problems <- function(problemlist) {
  problems <- problemlist$problems %>%
    map_dfr(bind_rows, .id=".id") %>%
    rename(run=.id) %>%
    group_by(modelid) %>%
    summarize(bad_proportion = n()/reps, bad_count = n(), divergences_mean=mean(divergences), bad_rhats_mean=mean(bad_rhats), bad_neff_mean=mean(bad_neff))
  
  return(problems)
}

problems_bb <- table_problems(extracts_indir_beta_beta)
problems_ba <- table_problems(extracts_indir_beta_alpha)
problems_ab <- table_problems(extracts_indir_alpha_beta)
problems_aa <- table_problems(extracts_indir_alpha_alpha)
  
knitr::kable(problems_bb, caption = "Beta data, beta model")
knitr::kable(problems_ab, caption = "Alpha data, beta model")

knitr::kable(problems_ba, caption = "Beta data, alpha model")
knitr::kable(problems_aa, caption = "Alpha data, alpha model")


```

Fit on intercept models was fine no matter how data was simulated. Going forward, I'll only be using the intercept models. 

```{r}
# pull params from fits
params_ba <- extracts_indir_beta_alpha$pars %>%
  map_dfr(bind_rows, .id = ".id") %>%
  rename(run=.id) %>%
  split(.$modelid)

params_aa <- extracts_indir_alpha_alpha$pars %>%
  map_dfr(bind_rows, .id = ".id") %>%
  rename(run=.id) %>%
  split(.$modelid)


```

```{r plotIndirParams, fig.height=3, fig.width=4}

parplot <- function(modelpars) {
p1 <- ggplot(modelpars, aes(x=beta_model, color=run)) +
    geom_density()+
    theme(legend.position="none") +
    xlab("beta") +
    geom_vline(xintercept = unique(modelpars$beta_true))

p2 <- ggplot(modelpars, aes(x=c.1_model, color=run)) +
    geom_density() +
    geom_density(aes(x=c.2_model)) +
    theme(legend.position="none") +
    xlab("cutpoints") +
    geom_vline(xintercept = c(unique(modelpars$c.1_true), unique(modelpars$c.2_true)))

p3 <- ggplot(modelpars, aes(x=h.1_group.1_model, color=run)) +
    geom_density() +
    geom_density(aes(x=h.2_group.1_model)) +
    theme(legend.position="none") +
    xlab("group 1 transitions") +
    geom_vline(xintercept = c(unique(modelpars$h.1_group.1_true), unique(modelpars$h.2_group.1_true)))

cowplot::plot_grid(p1, p2, p3, labels=paste("model", modelpars$modelid_true))

}

map(params_ba[sort(base::sample(1:12, 5))], parplot) # pick 5 models at random to plot
map(params_aa[sort(base::sample(1:12, 5))], parplot)

```

# Recapture rate

```{r indirHDPI, message=FALSE, warning=FALSE, cache=TRUE}
# calculate whether true value is in HPDI
# 
HPDIlow <- function(x, prob) {
    HPDI <- rethinking::HPDI(x, prob=prob)
    return(HPDI[1])
}

HPDIhigh <- function(x, prob) {
    HPDI <- rethinking::HPDI(x, prob=prob)
    return(HPDI[2])
}

calc_HPDI <- function(params, prob) {
    params <- params %>%
        tidyr::pivot_longer(ends_with("model"), names_to = "param", values_to = "param_value") %>%
        filter(param != "lp___model") %>%
        tidyr::extract(param, into="param", regex="(.*)_model") %>% # drop model ending
        rename(modelid=modelid_true)

    # calculate bottom and top of HPDI at prob for each model run and each parameter
    low <- params %>%
        group_by(modelid, run, param) %>%
        summarise(low= HPDIlow(param_value, prob=prob))
    high <- params %>%
        group_by(modelid, run, param) %>%
        summarise(high= HPDIhigh(param_value, prob=prob))


    hdpis <- dplyr::full_join(low, high)

    # true params
    true <- params %>% dplyr::summarise_at(vars(ends_with("true")), unique)
    colnames(true) <- stringr::str_replace(colnames(true), "_true", "")
    true <- select(true, c("c.1", "c.2", "beta", starts_with("alpha"), starts_with("h."))) %>%
        tidyr::pivot_longer(cols=c("c.1", "c.2", "beta", starts_with("alpha"), starts_with("h.")), names_to = "param", values_to="true")

    # combine true and hdpis for comparison
    compframe <- full_join(hdpis, true)


    # true param in interval?
    tf <- compframe %>% mutate(inint = true > low & true < high)
    return(tf)
}

# For each parameter (5) in each model (27) in each run (30), is a given parameter in the 50% or 90% HPDI? modelpars is a list of dataframes. Each dataframe in the list contains parameters from 30 runs of 1 model along with the true parameters used to simulate the datasets.
# output is a list of 2 dataframes 4050 rows each (5x27x30) - with each parameter estimated by the model and an inint column with TRUE if it falls in the HPDI interval and FALSE if not.
which_params_recaptured <- function(modelpars) {
    in50 <- map(modelpars, calc_HPDI, prob=0.5)

    #in75 <- map(params_indir, calc_HPDI, prob=0.75)

    in90 <- map(modelpars, calc_HPDI, prob=.90)

    # recaptured parameters (refactor this later so it's all in one df
    perform50 <- map_dfr(in50, bind_rows)
    perform90 <- map_dfr(in90, bind_rows)

    return(list(fifty = perform50, ninety=perform90))
}


recaptured_ba <- which_params_recaptured(params_ba)
recaptured_aa <- which_params_recaptured(params_aa)

calc_prop_recaptured_overall <- function(inint, truepars) {

# trues <- inint$fifty %>%
#   ungroup() %>%
#   select(modelid, param, true) %>%
#   distinct()
# 
# nas <- which(is.na(inint$fifty$inint))
# inint$fifty[nas,]

    # proportion of parameters recaptured
    prop_recaptured50 <- inint$fifty %>%
      filter(param != "sigma_group") %>%
        group_by(modelid, run)  %>%
        summarise(captured = sum(inint, na.rm = TRUE))  %>%
        summarise(mean_captured = mean(captured), sd_captured=sd(captured)) %>%
        full_join(truepars) %>%
        arrange(beta, desc(mean_captured))


    prop_recaptured90 <- inint$ninety %>%
      filter(param != "sigma_group") %>%
        group_by(modelid, run) %>%
        summarise(captured = sum(inint, na.rm=TRUE)) %>%
        summarise(mean_captured = mean(captured), sd_captured=sd(captured)) %>%
        full_join(truepars) %>%
        arrange(beta, desc(mean_captured))

    return(list(fifty = prop_recaptured50, ninety = prop_recaptured90))
}

prop_recaptured_ba <- calc_prop_recaptured_overall(recaptured_ba, truepars=parframe_indir)
prop_recaptured_aa <- calc_prop_recaptured_overall(recaptured_aa, truepars=parframe_indir)

calc_recaptured_by_param <- function(inint, truepars) {
    perform50_summary <- inint$fifty %>%
      filter(param != "sigma_group") %>%
        group_by(modelid, param) %>%
        summarise(prop_inint = mean(inint)) %>%
        left_join(truepars)

    perform90_summary <- inint$ninety %>%
      filter(param != "sigma_group") %>%
        group_by(modelid, param) %>%
        summarise(prop_inint = mean(inint)) %>%
        left_join(truepars)

    return(list(fifty=perform50_summary, ninety=perform90_summary))
}

prop_recaptured_by_param_ba <- calc_recaptured_by_param(recaptured_ba, parframe_indir) 
prop_recaptured_by_param_aa <- calc_recaptured_by_param(recaptured_aa, parframe_indir) 
```




```{r plotIndirRecaptureoverall, caption="Number of parameters recaptured by each model, averaged across model runs", fig.width=7, fig.height=4}
ggplot(prop_recaptured_ba$fifty, aes(x=as.factor(anchor), y=as.factor(beta_rate), fill=mean_captured)) + 
  geom_tile(colour="white") +
  geom_text(aes(label=modelid)) +
  facet_wrap("transition", scales="free") +
  ggtitle("Proportion of parameters recaptured in 50% HPDI", subtitle = "faceted by transition speed in simulated dataset \n labeled with modelid") +
  scale_fill_viridis_c() +
  ylab("beta_rate")
# ggplot(prop_recaptured_aa$fifty, aes(x=as.factor(anchor), y=as.factor(beta_rate), fill=mean_captured)) + 
#   geom_tile(colour="white") +
#   geom_text(aes(label=modelid)) +
#   facet_wrap("transition", scales="free") +
#   ggtitle("Proportion of parameters recaptured in 50% HPDI", subtitle = "faceted by transition speed in simulated dataset \n labeled with modelid") +
#   scale_fill_viridis_c(limits=c(0,10)) +
#   ylab("beta_rate")

ggplot(prop_recaptured_ba$ninety, aes(x=as.factor(anchor), y=as.factor(beta_rate), fill=mean_captured)) + 
  geom_tile(colour="white") +
  geom_text(aes(label=modelid)) +
  facet_wrap("transition", scales="free") +
  ggtitle("Proportion of parameters recaptured in 90% HPDI",subtitle = "faceted by transition speed in simulated dataset \n labeled with modelid") +
  scale_fill_viridis_c(limits=c(0,17)) +
  ylab("beta_rate")

# ggplot(prop_recaptured_aa$ninety, aes(x=as.factor(anchor), y=as.factor(beta_rate), fill=mean_captured)) + 
#   geom_tile(colour="white") +
#   geom_text(aes(label=modelid)) +
#   facet_wrap("transition", scales="free") +
#   ggtitle("Proportion of parameters recaptured in 90% HPDI",subtitle = "faceted by transition speed in simulated dataset \n labeled with modelid") +
#   scale_fill_viridis_c(limits=c(0,10)) +
#   ylab("beta_rate")
```
Model is better able to return parameters when data generating process in on intercept.

But what about the relationship between the variables - the transition points?

```{r plotIndirRecapture}

ggplot(prop_recaptured_by_param_ba$fifty, aes(x=param, y=as.factor(modelid), fill=prop_inint)) + 
  geom_tile(color="white") +
  scale_fill_viridis_c()  +
  geom_text(aes(label=paste(anchor, beta_rate, sep="\n")), size=2.5) +
  facet_wrap("transition", scales="free") +
  ggtitle("Parameters recaptured in 50% HPDI", subtitle = "faceted by transition speed (beta) in simulated dataset \n with anchor and beta rate labels") +
  theme(legend.position = "top") +
  ylab("model id")  +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(prop_recaptured_by_param_ba$ninety, aes(x=param, y=as.factor(modelid), fill=prop_inint)) + 
  geom_tile(color="white") +
  scale_fill_viridis_c()  +
  geom_text(aes(label=paste(anchor, beta_rate, sep="\n")), size=2.5) +
  facet_wrap("transition", scales="free") +
  ggtitle("Parameters recaptured in 90% HPDI", subtitle = "faceted by transition speed (beta) in simulated dataset\n with anchor and beta rate labels") +
  theme(legend.position = "top") +
  ylab("model id") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

Only very small deviations from h (or alpha) are recaptured.
