---
title: "Choosing priors in an ordinal logistic model"
subtitle: "with covariate and group effects"
author: "Susannah Tysor"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    theme: flatly
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message=FALSE)
```

```{r}
library(dplyr)
library(rstan)
library(tidyr)
library(purrr)
library(cowplot)
library(bayesplot)
library(ggplot2)

rstan_options(auto_write=TRUE)
```

```{r depends}
source('prior_analysis_groups_functions.R')
```

```{r global}
# each version of a model should be run how many times?
reps <- 5
```

# Background

[Previously](https://scisus.github.io/ordinal_logistic_prior/prior_analysis.html), I considered whether a gamma or an induced dirichlet prior on cut points in an ordinal logistic model worked better for the kind of data I'm considering. Neither was very promising, but because of problems with convergence, etc. in models with the gamma prior, I'm testing group effects with the induced dirichlet.

In this model, the state of flowering depends on how many forcing units have accumulated. 

There are three possible states: 1-not yet flowering, 2- flowering, 3- done flowering. 

$x$ is accumulated forcing: when flowering was observed, how much warmth had the population/tree been exposed to since January 1? $x$ is always positive (and always increases monotonically through time - though time is abstracted out of this model).

$\beta$ describes how fast the transition occurs - small $\beta$s make the transition from between states occur over a wider range of $x$'s. (Translated from forcing units to days, this answers a question like "does the population transition between states over 1 day, 3 days, a week?" We work in forcing unit space because the trees respond to temperature, not time - and no spring heats up exactly the same so dates are kind of useless for prediction.) $\beta$ is always positive.

In [the case without groups](https://scisus.github.io/ordinal_logistic_prior/prior_analysis.html), an ordinal logistic model with an induced dirichlet prior on cutpoints can struggle to recapture $\beta$ and cut points $c$, but it is pretty good at capturing the relationship between $\beta$ and $c$: $h = \frac{c}{\beta}$, which is the point at which half the trees in a population have transitioned or the point at which an individual tree is 50% likely to have transitioned. 

In the previous analysis, no groups were considered. In reality, I want to know if things like site, provenance, and clone affect $h$.

## Goals
1 - Generate data with an ordinal logistic model 
   - With linear model structure $\beta x + \alpha$
2 - Fit model with Stan
3 - Determine whether $\beta$, $\beta_{site_i}$, \alpha$, $c$, or $h$ can be returned.


I'll simulate data for 10 groups with `N=100` observations for each group. Each group's $h$ are shifted by $h_mod$, which is drawn from a $\mathcal{N}(0,\sigma)$. Data is simulated for two transition speeds, $\beta=1$ and $\beta=2$.

First we'll do this with null effects ($\sigma=0$), then with a relatively large range of effects (\sigma = 1).

# Can null group effects be detected?

Simulate data from an ordinal logistic model where there are 10 groups, but none of the groups have an effect.

The Stan model for data simulation is:

```{r}
writeLines(readLines("simulate/covar_group_alpha_sim.stan"))
```
Plots of simulated data for each group should look roughly identical.

```{r nullGroupSimulation, fig.height=11, fig.width=5, fig.cap="Simulated data in each group. Since groups have no effect in test, all groups should look more or less identical.}

G = 10
h_mod0 <- rep(0, G)

simulation_input <- set_simulation_parameters(G=G, hmod=h_mod0)


simdat_alpha <- purrr::map(.x=simulation_input$inputlist, .f=simulate_data)

plot_simulated_data(simdat_alpha, simulation_input$inputlist)
```

## Estimate parameters

Next we'll check whether models can accurately recapture parameters. Based on findings from the no-group investigation, we'll create models with an exponential prior on $\beta$ with a rate of 1, 2, or 3 and the anchor for the dirichlet inducing the priors on cutpoints at 10 and 20. 



```{r params}

beta_rate <- c(1:3) # rate parameters for exponential prior on beta
anchor <- c(10, 20) # different anchor parameters for induced dirichlet prior

# make a nice dataframe with all combinations params used to simulate data and model params used to try to recover those params
# 

parframe_indir <- simulation_input$pars %>% 
  dplyr::select(transition, beta, c.1, c.2, group, alpha_group) %>%
  tidyr::pivot_wider(names_from = group, names_prefix = "alpha_g.", values_from = alpha_group) %>% # put in wide format
  merge(y= beta_rate) %>%
    rename(beta_rate=y) %>%
    merge(y=anchor) %>%
    rename(anchor=y)
parframe_indir$modelid <- 1:nrow(parframe_indir) #label the models

# make a wide format with beta_group cols and merge with parframe_indir


parlist_indir <- make_parframe_list(parframe_indir)
```

```{r indirRecapture, include=FALSE}

# run all models, parallelized

# make a cluster using half your cores
no_cores <- parallel::detectCores()/2
cl <- parallel::makeCluster(no_cores)

# export the stuff you need to run on the cluster
parallel::clusterExport(cl, c("fit_indir_model", "parlist_indir", "simdat_beta", "simdat_alpha"))
parallel::clusterEvalQ(cl, c(library(rstan), library(StanHeaders)))

reps=10
for (i in 1:reps) {
  fits_indir <- parallel::parLapply(cl, parlist_indir, function(x) {fit_indir_model(simdatlist = simdat_beta, pars=x, modification="beta")})
  saveRDS(fits_indir, file = paste0("induced_dirichlet/group_runs/beta_dat_beta_mod/run", i, ".rds"))
  rm(fits_indir)
  gc()
}

for (i in 1:reps) {
    fits_indir <- parallel::parLapply(cl, parlist_indir, function(x) {fit_indir_model(simdatlist = simdat_beta, pars=x, modification="alpha")})
  saveRDS(fits_indir, file = paste0("induced_dirichlet/group_runs/beta_dat_alpha_mod/run", i, ".rds"))
  rm(fits_indir)
  gc()
}

for (i in 1:reps) {  
    fits_indir <- parallel::parLapply(cl, parlist_indir, function(x) {fit_indir_model(simdatlist = simdat_alpha, pars=x, modification="beta")})
  saveRDS(fits_indir, file = paste0("induced_dirichlet/group_runs/alpha_dat_beta_mod/run", i, ".rds"))
  rm(fits_indir)
  gc()
}

for (i in 1:reps) {  
    fits_indir <- parallel::parLapply(cl, parlist_indir, function(x) {fit_indir_model(simdatlist = simdat_alpha, pars=x, modification="alpha")})
  saveRDS(fits_indir, file = paste0("induced_dirichlet/group_runs/alpha_dat_alpha_mod/run", i, ".rds"))
  rm(fits_indir)
  gc()
}

parallel::stopCluster(cl) #close the cluster

```

```{r readIndirModels, warning=FALSE, cache=TRUE}

# pull in parameters and info on divergences, etc from saved stanfit objects
# very slow step. consider parallelizing to the extent your ram can handle
# 


  



No obvious problems with the model/fit.




}

dirs <- list.dirs("induced_dirichlet/group_runs/")
extracts_indir_beta_beta <- extract_pars_and_problems(path="induced_dirichlet/group_runs/beta_dat_beta_mod/", parlist=parlist_indir, modelstr = "beta")
extracts_indir_beta_alpha <- extract_pars_and_problems(path="induced_dirichlet/group_runs/beta_dat_alpha_mod/", parlist=parlist_indir, modelstr = "alpha")
extracts_indir_alpha_beta <- extract_pars_and_problems(path="induced_dirichlet/group_runs/alpha_dat_beta_mod/", parlist=parlist_indir, modelstr = "beta")
extracts_indir_alpha_alpha <- extract_pars_and_problems(path="induced_dirichlet/group_runs/alpha_dat_alpha_mod/", parlist=parlist_indir, modelstr = "alpha")


```

Models with the effect on the slope have serious fitting issues. Lots of divergences. Models with the effect on intercept don't have fitting problems.

```{r indirModelCheck}

table_problems <- function(problemlist) {
  problems <- problemlist$problems %>%
    map_dfr(bind_rows, .id=".id") %>%
    rename(run=.id) %>%
    group_by(modelid) %>%
    summarize(bad_proportion = n()/reps, bad_count = n(), divergences_mean=mean(divergences), bad_rhats_mean=mean(bad_rhats), bad_neff_mean=mean(bad_neff))
  
  return(problems)
}

problems_bb <- table_problems(extracts_indir_beta_beta)
problems_ba <- table_problems(extracts_indir_beta_alpha)
problems_ab <- table_problems(extracts_indir_alpha_beta)
problems_aa <- table_problems(extracts_indir_alpha_alpha)
  
knitr::kable(problems_bb, caption = "Beta data, beta model")
knitr::kable(problems_ab, caption = "Alpha data, beta model")

knitr::kable(problems_ba, caption = "Beta data, alpha model")
knitr::kable(problems_aa, caption = "Alpha data, alpha model")


```

Fit on intercept models was fine no matter how data was simulated. Going forward, I'll only be using the intercept models. 

```{r}
# pull params from fits
params_ba <- extracts_indir_beta_alpha$pars %>%
  map_dfr(bind_rows, .id = ".id") %>%
  rename(run=.id) %>%
  split(.$modelid)

params_aa <- extracts_indir_alpha_alpha$pars %>%
  map_dfr(bind_rows, .id = ".id") %>%
  rename(run=.id) %>%
  split(.$modelid)


```

```{r plotIndirParams}
```{r plotIndirParams, fig.height=3, fig.width=4}



map(params_ba[sort(base::sample(1:12, 5))], parplot) # pick 5 models at random to plot
map(params_aa[sort(base::sample(1:12, 5))], parplot)

```

# Recapture rate

```{r indirHDPI, message=FALSE, warning=FALSE, cache=TRUE}

#recaptured_ba <- which_params_recaptured(params_ba)
recaptured_aang <- params_aang %>%
  split(.$modelid) %>%
  which_params_recaptured()



#prop_recaptured_by_param_ba <- calc_recaptured_by_param(recaptured_ba, parframe_indir) 
prop_recaptured_by_param_aang <- calc_recaptured_by_param(recaptured_aang, parframe_indir)  %>%
  purrr::map_dfr(bind_rows, .id=".id")
```





recaptured_ba <- which_params_recaptured(params_ba)
recaptured_aa <- which_params_recaptured(params_aa)

calc_prop_recaptured_overall <- function(inint, truepars) {


prop_recaptured_ba <- calc_prop_recaptured_overall(recaptured_ba, truepars=parframe_indir)
prop_recaptured_aa <- calc_prop_recaptured_overall(recaptured_aa, truepars=parframe_indir)

calc_recaptured_by_param <- function(inint, truepars) {
    perform50_summary <- inint$fifty %>%
      filter(param != "sigma_group") %>%
        group_by(modelid, param) %>%
        summarise(prop_inint = mean(inint)) %>%
        left_join(truepars)

    perform90_summary <- inint$ninety %>%
      filter(param != "sigma_group") %>%
        group_by(modelid, param) %>%
        summarise(prop_inint = mean(inint)) %>%
        left_join(truepars)

    return(list(fifty=perform50_summary, ninety=perform90_summary))
}

prop_recaptured_by_param_ba <- calc_recaptured_by_param(recaptured_ba, parframe_indir) 
prop_recaptured_by_param_aa <- calc_recaptured_by_param(recaptured_aa, parframe_indir) 
```




```{r plotIndirRecaptureoverall, caption="Number of parameters recaptured by each model, averaged across model runs", fig.width=7, fig.height=4}
ggplot(prop_recaptured_ba$fifty, aes(x=as.factor(anchor), y=as.factor(beta_rate), fill=mean_captured)) + 
  geom_tile(colour="white") +
  geom_text(aes(label=modelid)) +
  facet_wrap("transition", scales="free") +
  ggtitle("Proportion of parameters recaptured in 50% HPDI", subtitle = "faceted by transition speed in simulated dataset \n labeled with modelid") +
  scale_fill_viridis_c() +
  ylab("beta_rate")
# ggplot(prop_recaptured_aa$fifty, aes(x=as.factor(anchor), y=as.factor(beta_rate), fill=mean_captured)) + 
#   geom_tile(colour="white") +
#   geom_text(aes(label=modelid)) +
#   facet_wrap("transition", scales="free") +
#   ggtitle("Proportion of parameters recaptured in 50% HPDI", subtitle = "faceted by transition speed in simulated dataset \n labeled with modelid") +
#   scale_fill_viridis_c(limits=c(0,10)) +
#   ylab("beta_rate")

ggplot(prop_recaptured_ba$ninety, aes(x=as.factor(anchor), y=as.factor(beta_rate), fill=mean_captured)) + 
  geom_tile(colour="white") +
  geom_text(aes(label=modelid)) +
  facet_wrap("transition", scales="free") +
  ggtitle("Proportion of parameters recaptured in 90% HPDI",subtitle = "faceted by transition speed in simulated dataset \n labeled with modelid") +
  scale_fill_viridis_c(limits=c(0,17)) +
  ylab("beta_rate")

# ggplot(prop_recaptured_aa$ninety, aes(x=as.factor(anchor), y=as.factor(beta_rate), fill=mean_captured)) + 
#   geom_tile(colour="white") +
#   geom_text(aes(label=modelid)) +
#   facet_wrap("transition", scales="free") +
#   ggtitle("Proportion of parameters recaptured in 90% HPDI",subtitle = "faceted by transition speed in simulated dataset \n labeled with modelid") +
#   scale_fill_viridis_c(limits=c(0,10)) +
#   ylab("beta_rate")
```
Model is better able to return parameters when data generating process in on intercept.

But what about the relationship between the variables - the transition points?

```{r plotIndirRecapture}

ggplot(prop_recaptured_by_param_ba$fifty, aes(x=param, y=as.factor(modelid), fill=prop_inint)) + 
  geom_tile(color="white") +
  scale_fill_viridis_c()  +
  geom_text(aes(label=paste(anchor, beta_rate, sep="\n")), size=2.5) +
  facet_wrap("transition", scales="free") +
  ggtitle("Parameters recaptured in 50% HPDI", subtitle = "faceted by transition speed (beta) in simulated dataset \n with anchor and beta rate labels") +
  theme(legend.position = "top") +
  ylab("model id")  +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(prop_recaptured_by_param_ba$ninety, aes(x=param, y=as.factor(modelid), fill=prop_inint)) + 
  geom_tile(color="white") +
  scale_fill_viridis_c()  +
  geom_text(aes(label=paste(anchor, beta_rate, sep="\n")), size=2.5) +
  facet_wrap("transition", scales="free") +
  ggtitle("Parameters recaptured in 90% HPDI", subtitle = "faceted by transition speed (beta) in simulated dataset\n with anchor and beta rate labels") +
  theme(legend.position = "top") +
  ylab("model id") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

Only very small deviations from h (or alpha) are recaptured.
